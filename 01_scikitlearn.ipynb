{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce tutoriel reprend celui sur le site de [scikit learn](https://docs.google.com/spreadsheets/d/15x0AUKgeUqtcExbmE3eHlNjaE_WFhaNpB9dQEgmVevc/edit#gid=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I Analyse du problème"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utilisé un dataset inclu dans scikit learn.\n",
    "\n",
    "Il contient une série de texte classé par catégorie. Nous allons nous ateler à une tâche de classification supervisée dont le but sera de retrouver cette catégorie.\n",
    "\n",
    "Nous commençons par selectionner un sous ensemble de ces catégories pour que le dataset ne soit pas trop important:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe ensuite le jeu de données correspondant à ces catégories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut afficher les premières lignes d'un des fichiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II Choix de l'encodage et du pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Théorie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn implémente différent encodage ([doc](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text)):\n",
    "- CountVectorizer: Transforme une série de documents en une matrice de comptage (Bag of Word)\n",
    "- HashingVectorizer: Transforme une série de documents en une matrice d'occurence\n",
    "- TfidfVectorizer: Transforme une série de documents en une matrice de fréquence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous appliquerons dans un premier temps CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans scikit learn, le pre-processing est réalisé via les paramètres de la classe d'encodage.\n",
    "On a en effet les paramètres suivants (entre parenthèse la valeur par défaut):\n",
    "- strip_accents (FALSE): supprime tous les accents (réduit la taille du vocabulaire)\n",
    "- lowercase (TRUE): convertie tous les caractères (réduit la taille du vocabulaire)\n",
    "- stop_words (None): permet d'ajouter une liste de stop word ou d'utiliser une liste par défaut {english}\n",
    "- max_df (1.0): ignore les mots qui ont une fréquence trop élevée dans le dataset (autre manière de gérer les stopwords)\n",
    "- min_df (1): ignore les mots présents moins de fois que le seuil.\n",
    "- analyzer (word) : Qu'est ce qui constitue une token (une unité de texte) {‘word’, ‘char’, ‘char_wb’} or callable (callable permet d'utiliser un preprocessing externe)\n",
    "- ngram_range (1,1): taille du n-gram à analyser\n",
    "- vocabulary: permet de proposer un vocabulaire précis\n",
    "\n",
    "Nous n'avons pas toutes les options de pre processing comme ce qui est inclu dans les packages comme nltk ou spacy mais nous verons plus tard qu'il sera possible de les utilser dans scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Pratique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons donc la matrice de comptage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de documents dans le jeu d'entraonement: 2257\n",
      "dimension de la matrice de comptage: (2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "# Dans notre jeu d'entrainement il y a 2257 documents\n",
    "print(f\"nombre de documents dans le jeu d'entrainement: {len(twenty_train.data)}\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "# On commence avec un preprocessing minimal (lower, token = word)\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "print(f\"dimension de la matrice de comptage: {X_train_counts.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après la dimension de la matrice de comptage on déduit qu'il y a 35788 mots dans notre vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n",
      "9338\n",
      "15576\n",
      "32142\n"
     ]
    }
   ],
   "source": [
    "# on peut retrouver l'indexe de chaque mot\n",
    "print(count_vect.vocabulary_.get(u'algorithm'))\n",
    "print(count_vect.vocabulary_.get(u'computer'))\n",
    "print(count_vect.vocabulary_.get(u'good'))\n",
    "print(count_vect.vocabulary_.get(u'the'))\n",
    "\n",
    "# plus un mot est fréquent plus sont indexe est elevé "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III Entainement et prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne reste plus qu'à entrainer un modèle qui prendra pour features la matrice construite et pour target le label de chacun des documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_counts = count_vect.transform(twenty_test.data)\n",
    "predicted = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9340878828229028"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(twenty_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.92      0.90      0.91       319\n",
      "         comp.graphics       0.95      0.95      0.95       389\n",
      "               sci.med       0.96      0.91      0.93       396\n",
      "soc.religion.christian       0.91      0.97      0.94       398\n",
      "\n",
      "              accuracy                           0.93      1502\n",
      "             macro avg       0.93      0.93      0.93      1502\n",
      "          weighted avg       0.93      0.93      0.93      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "predicted = clf.predict(X_new_counts)\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV Tuning du pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée pour cela un Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__strip_accents': [None, 'ascii'],\n",
    "    'vect__stop_words': [\"english\", None],\n",
    "    'vect__max_df': [1, 0.9,0.8,0.7],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "# on ne l'entraine que sur une partie du jeu de données\n",
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9778427486607931\n",
      "vect__max_df: 0.9\n",
      "vect__ngram_range: (1, 1)\n",
      "vect__stop_words: 'english'\n",
      "vect__strip_accents: None\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_grid = gs_clf.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.93      0.91      0.92       319\n",
      "         comp.graphics       0.95      0.96      0.96       389\n",
      "               sci.med       0.95      0.93      0.94       396\n",
      "soc.religion.christian       0.93      0.96      0.95       398\n",
      "\n",
      "              accuracy                           0.94      1502\n",
      "             macro avg       0.94      0.94      0.94      1502\n",
      "          weighted avg       0.94      0.94      0.94      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(twenty_test.target, predicted_grid, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V Preprocessing avec NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/charles/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "vect_nltk = CountVectorizer(tokenizer=LemmaTokenizer()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_nltk = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "gs_clf_nltk = text_clf_nltk.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_nltk = gs_clf_nltk.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.90      0.88      0.89       319\n",
      "         comp.graphics       0.92      0.94      0.93       389\n",
      "               sci.med       0.93      0.89      0.91       396\n",
      "soc.religion.christian       0.92      0.95      0.94       398\n",
      "\n",
      "              accuracy                           0.92      1502\n",
      "             macro avg       0.92      0.91      0.91      1502\n",
      "          weighted avg       0.92      0.92      0.92      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(twenty_test.target, predicted_nltk, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici les résultats sont moins bon mais nous n'avons pas tuné les modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI Exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons découvrir tous les modèles suivant au travers de l'exemple d'une compétition kaggle.\n",
    "L'objectif de cette [compétition](https://www.kaggle.com/competitions/quora-insincere-questions-classification/data?select=train.csv) est de déterminer si des questions postées sur le site Quora sont sincères ou non."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consignes:\n",
    "- Commencez par lire les consignes de la compétition pour lire les enjeux, repérer notament la métrique d'interet\n",
    "- Télécharger seulement le train set, nous travaillerons dessus.\n",
    "- Mettez en place un MLflow avec un projet spécifique. Pour tous les modèles que vous lancerez faites remonter spécifiquement le F1 score et des tags correspondant au modèle (quel préprocessing (steaming, url hangling), quel encodage (tf, tfidf, count vect, Word2Vect...), quel modèle (regresison, réseau de neurones)). Si vous lancez plusieurs modèles d'une meme catégorie pensez également à remonter les hyperparamètres modifiés. \n",
    "- Sur le jeu de données, lancez en vous aidant de scikit learn:\n",
    "    - un count vectoriser\n",
    "    - un tf\n",
    "    - un tf idf\n",
    " Vous avez le choix du modèle, vous pouvez meme si vous avez le temps faire un pycaret entre votre base encodée et votre target et tuner les hyperparamètres.\n",
    " - Intégrez ensuite si vous avez le temps du preprocessing avec NLTK.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6e043ccc4ff5f6895d6ef4ef51b514d0f7ca0307d37f45ef7621519e85018ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
